"""
æ—¶é—´åŒæ­¥éŸ³é¢‘åˆå¹¶å™¨
ç”¨äºå°†ç¿»è¯‘åçš„éŸ³é¢‘ç‰‡æ®µæŒ‰æ­£ç¡®çš„æ—¶é—´æˆ³åˆå¹¶åˆ°å®Œæ•´çš„éŸ³é¢‘è½¨é“ä¸­
"""

import os
import subprocess
import tempfile
import logging
from typing import List, Dict, Any, Optional
import numpy as np
import librosa
import soundfile as sf
from .output_manager import OutputManager, StepNumbers


class TimestampedAudioMerger:
    """æ—¶é—´åŒæ­¥éŸ³é¢‘åˆå¹¶å™¨ç±»"""
    
    def __init__(self, config: Dict[str, Any]):
        """
        åˆå§‹åŒ–æ—¶é—´åŒæ­¥éŸ³é¢‘åˆå¹¶å™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
        
        # éŸ³é¢‘å‚æ•°
        self.sample_rate = config.get("audio", {}).get("sample_rate", 44100)
        self.audio_format = config.get("audio", {}).get("format", "wav")
        
        # æ—¶é•¿æ§åˆ¶å‚æ•°
        self.max_speed_ratio = 2.0  # æœ€å¤§å…è®¸å€é€Ÿï¼ˆ2.0å€é€Ÿï¼Œè¶…è¿‡æ­¤å€é€Ÿåˆ™è£å‰ªï¼‰
        
        self.logger.info("æ—¶é—´åŒæ­¥éŸ³é¢‘åˆå¹¶å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _recalculate_segment_timestamps(self, segments: List[Dict[str, Any]], total_duration: float) -> List[Dict[str, Any]]:
        """
        é‡æ–°è®¡ç®—åˆ†æ®µæ—¶é—´æˆ³ï¼ŒåŸºäºå®é™…éŸ³é¢‘æ—¶é•¿ï¼Œä½†ä¿æŒåŸå§‹è§†é¢‘æ€»æ—¶é•¿
        
        Args:
            segments: åŸå§‹åˆ†æ®µåˆ—è¡¨
            total_duration: åŸå§‹è§†é¢‘æ€»æ—¶é•¿
            
        Returns:
            é‡æ–°è®¡ç®—æ—¶é—´æˆ³åçš„åˆ†æ®µåˆ—è¡¨
        """
        self.logger.info("ğŸ”„ é‡æ–°è®¡ç®—åˆ†æ®µæ—¶é—´æˆ³ï¼ŒåŸºäºå®é™…éŸ³é¢‘æ—¶é•¿ï¼Œä¿æŒåŸå§‹è§†é¢‘æ€»æ—¶é•¿...")
        
        # æ”¶é›†æ‰€æœ‰æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶
        valid_segments = []
        total_audio_duration = 0.0
        
        for i, segment in enumerate(segments):
            audio_path = segment.get("audio_path", "")
            
            if not audio_path or not os.path.exists(audio_path):
                self.logger.warning(f"åˆ†æ®µ {i} éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡: {audio_path}")
                continue
            
            # è·å–å®é™…éŸ³é¢‘æ—¶é•¿
            actual_duration = self.get_original_audio_duration(audio_path)
            
            if actual_duration <= 0:
                self.logger.warning(f"åˆ†æ®µ {i} æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿ï¼Œè·³è¿‡")
                continue
            
            valid_segments.append((i, segment, actual_duration))
            total_audio_duration += actual_duration
        
        if not valid_segments:
            self.logger.error("æ²¡æœ‰æœ‰æ•ˆçš„éŸ³é¢‘åˆ†æ®µ")
            return segments
        
        # è®¡ç®—æ—¶é—´åˆ†é…ç­–ç•¥
        if total_audio_duration <= total_duration:
            # å¦‚æœæ€»éŸ³é¢‘æ—¶é•¿ <= è§†é¢‘æ—¶é•¿ï¼Œç›´æ¥æŒ‰é¡ºåºåˆ†é…
            self.logger.info(f"æ€»éŸ³é¢‘æ—¶é•¿ ({total_audio_duration:.2f}s) <= è§†é¢‘æ—¶é•¿ ({total_duration:.2f}s)ï¼Œç›´æ¥æŒ‰é¡ºåºåˆ†é…")
            recalculated_segments = []
            current_time = 0.0
            
            for i, segment, actual_duration in valid_segments:
                new_segment = segment.copy()
                new_segment['start'] = current_time
                new_segment['end'] = current_time + actual_duration
                
                self.logger.info(f"åˆ†æ®µ {i}: {segment.get('start', 0):.2f}s-{segment.get('end', 0):.2f}s -> {current_time:.2f}s-{current_time + actual_duration:.2f}s (å®é™…éŸ³é¢‘: {actual_duration:.3f}s)")
                
                recalculated_segments.append(new_segment)
                current_time += actual_duration
            
            # å¦‚æœè¿˜æœ‰å‰©ä½™æ—¶é—´ï¼Œç”¨é™éŸ³å¡«å……
            if current_time < total_duration:
                self.logger.info(f"å‰©ä½™æ—¶é—´: {total_duration - current_time:.2f}sï¼Œå°†åœ¨æœ«å°¾ç”¨é™éŸ³å¡«å……")
        else:
            # å¦‚æœæ€»éŸ³é¢‘æ—¶é•¿ > è§†é¢‘æ—¶é•¿ï¼Œéœ€è¦å‹ç¼©
            compression_ratio = total_duration / total_audio_duration
            self.logger.warning(f"æ€»éŸ³é¢‘æ—¶é•¿ ({total_audio_duration:.2f}s) > è§†é¢‘æ—¶é•¿ ({total_duration:.2f}s)ï¼Œéœ€è¦å‹ç¼© {compression_ratio:.2f} å€")
            
            recalculated_segments = []
            current_time = 0.0
            
            for i, segment, actual_duration in valid_segments:
                compressed_duration = actual_duration * compression_ratio
                new_segment = segment.copy()
                new_segment['start'] = current_time
                new_segment['end'] = current_time + compressed_duration
                
                self.logger.info(f"åˆ†æ®µ {i}: {segment.get('start', 0):.2f}s-{segment.get('end', 0):.2f}s -> {current_time:.2f}s-{current_time + compressed_duration:.2f}s (å‹ç¼©: {actual_duration:.3f}s -> {compressed_duration:.3f}s)")
                
                recalculated_segments.append(new_segment)
                current_time += compressed_duration
        
        self.logger.info(f"âœ… æ—¶é—´æˆ³é‡æ–°è®¡ç®—å®Œæˆï¼Œæ€»æ—¶é•¿: {total_duration:.2f}s")
        
        return recalculated_segments
    
    def create_timestamped_audio_track(self, segments: List[Dict[str, Any]], 
                                     total_duration: float, 
                                     output_path: str) -> Dict[str, Any]:
        """
        åˆ›å»ºæ—¶é—´åŒæ­¥çš„éŸ³é¢‘è½¨é“
        
        Args:
            segments: åŒ…å«æ—¶é—´æˆ³å’ŒéŸ³é¢‘æ–‡ä»¶è·¯å¾„çš„ç‰‡æ®µåˆ—è¡¨
            total_duration: åŸå§‹éŸ³é¢‘çš„æ€»æ—¶é•¿
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            
        Returns:
            åˆå¹¶ç»“æœå­—å…¸
        """
        self.logger.info(f"å¼€å§‹åˆ›å»ºæ—¶é—´åŒæ­¥éŸ³é¢‘è½¨é“ï¼Œæ€»æ—¶é•¿: {total_duration:.2f}ç§’")
        
        # ä¿æŒåŸå§‹åˆ†æ®µæ—¶é—´æˆ³ä¸å˜ï¼Œåªä¿®å¤å€é€Ÿå¤„ç†
        # segments = self._recalculate_segment_timestamps(segments, total_duration)
        
        try:
            # æ–¹æ³•1ï¼šä½¿ç”¨FFmpegåˆ›å»ºæ—¶é—´åŒæ­¥éŸ³é¢‘è½¨é“
            # ä¼˜å…ˆä½¿ç”¨librosaæ–¹æ³•ï¼Œå› ä¸ºå®ƒåœ¨éŸ³é‡ä¿æŒæ–¹é¢æ›´å¥½
            self.logger.info("ä½¿ç”¨librosaæ–¹æ³•è¿›è¡ŒéŸ³é¢‘åˆå¹¶ï¼ˆæ›´å¥½çš„éŸ³é‡ä¿æŒï¼‰")
            return self._create_with_librosa(segments, total_duration, output_path)
                
        except Exception as e:
            self.logger.error(f"åˆ›å»ºæ—¶é—´åŒæ­¥éŸ³é¢‘è½¨é“å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "output_path": output_path
            }
    
    def create_timestamped_audio_track_with_output_manager(self, segments: List[Dict[str, Any]], 
                                                          total_duration: float, 
                                                          output_manager: OutputManager) -> Dict[str, Any]:
        """
        ä½¿ç”¨OutputManageråˆ›å»ºæ—¶é—´åŒæ­¥çš„éŸ³é¢‘è½¨é“
        
        Args:
            segments: åŒ…å«æ—¶é—´æˆ³å’ŒéŸ³é¢‘æ–‡ä»¶è·¯å¾„çš„ç‰‡æ®µåˆ—è¡¨
            total_duration: åŸå§‹éŸ³é¢‘çš„æ€»æ—¶é•¿
            output_manager: è¾“å‡ºç®¡ç†å™¨å®ä¾‹
            
        Returns:
            åˆå¹¶ç»“æœå­—å…¸
        """
        self.logger.info(f"å¼€å§‹åˆ›å»ºæ—¶é—´åŒæ­¥éŸ³é¢‘è½¨é“ï¼Œæ€»æ—¶é•¿: {total_duration:.2f}ç§’")
        output_manager.log(f"æ­¥éª¤8å¼€å§‹: éŸ³é¢‘åˆå¹¶ï¼Œæ€»æ—¶é•¿ {total_duration:.2f}ç§’")
        
        try:
            # ä½¿ç”¨OutputManagerç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„
            output_path = output_manager.get_file_path(StepNumbers.STEP_8, "final_voice")
            
            # ä½¿ç”¨librosaæ–¹æ³•è¿›è¡ŒéŸ³é¢‘åˆå¹¶
            self.logger.info("ä½¿ç”¨librosaæ–¹æ³•è¿›è¡ŒéŸ³é¢‘åˆå¹¶ï¼ˆæ›´å¥½çš„éŸ³é‡ä¿æŒï¼‰")
            result = self._create_with_librosa(segments, total_duration, output_path)
            
            if result["success"]:
                output_manager.log(f"æ­¥éª¤8å®Œæˆ: éŸ³é¢‘åˆå¹¶å®Œæˆï¼Œè¾“å‡ºæ–‡ä»¶: {output_path}")
                # æ›´æ–°ç»“æœä¸­çš„æ–‡ä»¶è·¯å¾„
                result["output_path"] = output_path
            else:
                output_manager.log(f"æ­¥éª¤8å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            
            return result
                
        except Exception as e:
            self.logger.error(f"åˆ›å»ºæ—¶é—´åŒæ­¥éŸ³é¢‘è½¨é“å¤±è´¥: {e}")
            output_manager.log(f"æ­¥éª¤8å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "output_path": output_manager.get_file_path(8, "final_voice") if output_manager else None
            }
    
    def _create_with_ffmpeg(self, segments: List[Dict[str, Any]], 
                           total_duration: float, 
                           output_path: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨FFmpegåˆ›å»ºæ—¶é—´åŒæ­¥éŸ³é¢‘è½¨é“
        
        Args:
            segments: ç‰‡æ®µåˆ—è¡¨
            total_duration: æ€»æ—¶é•¿
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            # åˆ›å»ºä¸´æ—¶ç›®å½•
            temp_dir = tempfile.mkdtemp()
            
            # 1. åˆ›å»ºé™éŸ³è½¨é“ä½œä¸ºåŸºç¡€
            silent_audio = os.path.join(temp_dir, "silent.wav")
            self._create_silent_audio(total_duration, silent_audio)
            
            # 2. ä¸ºæ¯ä¸ªç‰‡æ®µåˆ›å»ºå¸¦æ—¶é•¿æ§åˆ¶çš„éŸ³é¢‘
            segment_files = []
            for i, segment in enumerate(segments):
                start_time = segment.get("start", 0.0)
                end_time = segment.get("end", 0.0)
                target_duration = end_time - start_time
                audio_file = segment.get("audio_path", "")
                
                if not audio_file or not os.path.exists(audio_file):
                    self.logger.warning(f"ç‰‡æ®µ {i} çš„éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
                    continue
                
                # æ£€æŸ¥å¹¶è°ƒæ•´éŸ³é¢‘æ—¶é•¿
                adjusted_audio = os.path.join(temp_dir, f"segment_{i:03d}_adjusted.wav")
                duration_adjusted = self._adjust_audio_duration_if_needed(
                    audio_file, target_duration, adjusted_audio
                )
                
                if duration_adjusted:
                    # åˆ›å»ºå¸¦å»¶è¿Ÿçš„éŸ³é¢‘æ–‡ä»¶
                    delayed_audio = os.path.join(temp_dir, f"segment_{i:03d}_delayed.wav")
                    self._add_delay_to_audio(adjusted_audio, start_time, delayed_audio)
                    segment_files.append(delayed_audio)
                else:
                    self.logger.warning(f"ç‰‡æ®µ {i} éŸ³é¢‘æ—¶é•¿è°ƒæ•´å¤±è´¥ï¼Œè·³è¿‡")
            
            # 3. åˆå¹¶æ‰€æœ‰éŸ³é¢‘
            if segment_files:
                self._merge_audio_files([silent_audio] + segment_files, output_path)
            else:
                # å¦‚æœæ²¡æœ‰æœ‰æ•ˆç‰‡æ®µï¼Œç›´æ¥å¤åˆ¶é™éŸ³æ–‡ä»¶
                import shutil
                shutil.copy2(silent_audio, output_path)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            import shutil
            shutil.rmtree(temp_dir)
            
            return {
                "success": True,
                "output_path": output_path,
                "segments_processed": len(segment_files),
                "total_duration": total_duration,
                "method": "ffmpeg"
            }
            
        except Exception as e:
            self.logger.error(f"FFmpegæ–¹æ³•å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "method": "ffmpeg"
            }
    
    def _create_with_librosa(self, segments: List[Dict[str, Any]], 
                            total_duration: float, 
                            output_path: str) -> Dict[str, Any]:
        """
        ä½¿ç”¨librosaåˆ›å»ºæ—¶é—´åŒæ­¥éŸ³é¢‘è½¨é“
        
        Args:
            segments: ç‰‡æ®µåˆ—è¡¨
            total_duration: æ€»æ—¶é•¿
            output_path: è¾“å‡ºè·¯å¾„
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            # ä¼˜åŒ–é‡‡æ ·ç‡é€‰æ‹©ç­–ç•¥ï¼šæ£€æµ‹å…‹éš†éŸ³é¢‘å’ŒèƒŒæ™¯éŸ³ä¹çš„é‡‡æ ·ç‡ï¼Œé€‰æ‹©è¾ƒé«˜çš„ä½œä¸ºç›®æ ‡é‡‡æ ·ç‡
            # å…ˆæ‰¾åˆ°ç¬¬ä¸€ä¸ªæœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶ï¼ŒåŠ è½½å®ƒæ¥è·å–åŸå§‹é‡‡æ ·ç‡
            detected_sample_rate = None
            first_valid_audio_file = None
            
            for segment in segments:
                audio_file = segment.get("audio_path", "")
                if audio_file and os.path.exists(audio_file):
                    first_valid_audio_file = audio_file
                    break
            
            if first_valid_audio_file:
                # åŠ è½½ç¬¬ä¸€ä¸ªåˆ†æ®µï¼ˆä¸æŒ‡å®šé‡‡æ ·ç‡ï¼‰ï¼Œè‡ªåŠ¨è·å–åŸå§‹é‡‡æ ·ç‡
                try:
                    _, detected_sample_rate = librosa.load(first_valid_audio_file, sr=None)
                    self.logger.info(f"ğŸµ æ£€æµ‹åˆ°å…‹éš†éŸ³é¢‘é‡‡æ ·ç‡: {detected_sample_rate} Hz")
                except Exception as e:
                    self.logger.warning(f"æ— æ³•æ£€æµ‹é‡‡æ ·ç‡ï¼Œä½¿ç”¨é…ç½®çš„é‡‡æ ·ç‡: {e}")
                    detected_sample_rate = self.sample_rate
            else:
                self.logger.warning("æœªæ‰¾åˆ°æœ‰æ•ˆçš„éŸ³é¢‘æ–‡ä»¶ï¼Œä½¿ç”¨é…ç½®çš„é‡‡æ ·ç‡")
                detected_sample_rate = self.sample_rate
            
            # æ£€æŸ¥èƒŒæ™¯éŸ³ä¹çš„é‡‡æ ·ç‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            output_dir = os.path.dirname(output_path)
            accompaniment_path = os.path.join(output_dir, "02_accompaniment.wav")
            accompaniment_sample_rate = None
            if os.path.exists(accompaniment_path):
                try:
                    _, accompaniment_sample_rate = librosa.load(accompaniment_path, sr=None)
                    self.logger.info(f"ğŸµ æ£€æµ‹åˆ°èƒŒæ™¯éŸ³ä¹é‡‡æ ·ç‡: {accompaniment_sample_rate} Hz")
                except Exception as e:
                    self.logger.warning(f"æ— æ³•æ£€æµ‹èƒŒæ™¯éŸ³ä¹é‡‡æ ·ç‡: {e}")
            
            # é€‰æ‹©ä¸¤è€…ä¸­è¾ƒé«˜çš„é‡‡æ ·ç‡ä½œä¸ºç›®æ ‡é‡‡æ ·ç‡ï¼ˆé¿å…é™é‡‡æ ·å¯¼è‡´éŸ³è´¨æŸå¤±ï¼‰
            if accompaniment_sample_rate is not None:
                actual_sample_rate = max(detected_sample_rate, accompaniment_sample_rate)
                if actual_sample_rate != detected_sample_rate:
                    self.logger.info(f"ğŸ“Š é€‰æ‹©è¾ƒé«˜é‡‡æ ·ç‡: {actual_sample_rate} Hzï¼ˆèƒŒæ™¯éŸ³ä¹ {accompaniment_sample_rate} Hz > å…‹éš†éŸ³é¢‘ {detected_sample_rate} Hzï¼‰ï¼Œå°†å‡é‡‡æ ·å…‹éš†éŸ³é¢‘è€Œéé™é‡‡æ ·èƒŒæ™¯éŸ³ä¹")
                else:
                    self.logger.info(f"ğŸ“Š é€‰æ‹©è¾ƒé«˜é‡‡æ ·ç‡: {actual_sample_rate} Hzï¼ˆå…‹éš†éŸ³é¢‘ {detected_sample_rate} Hz >= èƒŒæ™¯éŸ³ä¹ {accompaniment_sample_rate} Hzï¼‰")
            else:
                actual_sample_rate = detected_sample_rate
                self.logger.info(f"ğŸ“Š ä½¿ç”¨é‡‡æ ·ç‡: {actual_sample_rate} Hz è¿›è¡ŒéŸ³é¢‘åˆå¹¶ï¼ˆæ— èƒŒæ™¯éŸ³ä¹ï¼‰")
            
            # è®¡ç®—æ€»æ ·æœ¬æ•°ï¼ˆä½¿ç”¨æ£€æµ‹åˆ°çš„é‡‡æ ·ç‡ï¼‰
            total_samples = int(total_duration * actual_sample_rate)
            
            # åˆ›å»ºé™éŸ³è½¨é“
            audio_track = np.zeros(total_samples, dtype=np.float32)
            
            # åˆ›å»ºä¸´æ—¶ç›®å½•ç”¨äºå­˜å‚¨è°ƒæ•´åçš„éŸ³é¢‘
            import tempfile
            temp_dir = tempfile.mkdtemp()
            
            # å¤„ç†æ¯ä¸ªç‰‡æ®µ
            segments_processed = 0
            for i, segment in enumerate(segments):
                start_time = segment.get("start", 0.0)
                end_time = segment.get("end", 0.0)
                audio_file = segment.get("audio_path", "")
                
                # æ·»åŠ è¯¦ç»†è°ƒè¯•ä¿¡æ¯
                self.logger.info(f"ğŸ” å¤„ç†åˆ†æ®µ {i}:")
                self.logger.info(f"  æ—¶é—´æˆ³: {start_time:.2f}s - {end_time:.2f}s")
                self.logger.info(f"  åˆ†æ®µæ—¶é•¿: {end_time - start_time:.2f}s")
                self.logger.info(f"  éŸ³é¢‘æ–‡ä»¶: {audio_file}")
                
                if not audio_file or not os.path.exists(audio_file):
                    self.logger.warning(f"ç‰‡æ®µ {i} çš„éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_file}")
                    continue
                
                try:
                    # æ£€æŸ¥å¹¶è°ƒæ•´éŸ³é¢‘æ—¶é•¿
                    target_duration = end_time - start_time
                    adjusted_audio = os.path.join(temp_dir, f"segment_{i:03d}_adjusted.wav")
                    duration_adjusted = self._adjust_audio_duration_if_needed(
                        audio_file, target_duration, adjusted_audio
                    )
                    
                    # ä½¿ç”¨è°ƒæ•´åçš„éŸ³é¢‘æ–‡ä»¶ï¼ˆå¦‚æœè°ƒæ•´æˆåŠŸï¼‰æˆ–åŸå§‹æ–‡ä»¶
                    final_audio_file = adjusted_audio if duration_adjusted else audio_file
                    
                    # åŠ è½½éŸ³é¢‘æ–‡ä»¶ï¼ˆä½¿ç”¨ sr=None ä¿æŒåŸå§‹é‡‡æ ·ç‡ï¼Œå¦‚æœé‡‡æ ·ç‡ä¸ä¸€è‡´åˆ™é‡é‡‡æ ·åˆ°æ£€æµ‹åˆ°çš„é‡‡æ ·ç‡ï¼‰
                    audio_data, sr = librosa.load(final_audio_file, sr=None)
                    
                    # å¦‚æœé‡‡æ ·ç‡ä¸ä¸€è‡´ï¼Œé‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡ï¼ˆä½¿ç”¨é«˜è´¨é‡é‡é‡‡æ ·ç®—æ³•ï¼‰
                    if sr != actual_sample_rate:
                        if sr < actual_sample_rate:
                            self.logger.info(f"  ğŸ”„ é‡‡æ ·ç‡ä¸åŒ¹é… ({sr} Hz < {actual_sample_rate} Hz)ï¼Œå‡é‡‡æ ·åˆ° {actual_sample_rate} Hzï¼ˆä½¿ç”¨kaiser_bestç®—æ³•ï¼‰")
                        else:
                            self.logger.info(f"  ğŸ”„ é‡‡æ ·ç‡ä¸åŒ¹é… ({sr} Hz > {actual_sample_rate} Hz)ï¼Œé™é‡‡æ ·åˆ° {actual_sample_rate} Hzï¼ˆä½¿ç”¨kaiser_bestç®—æ³•ï¼‰")
                        audio_data = librosa.resample(audio_data, orig_sr=sr, target_sr=actual_sample_rate, res_type='kaiser_best')
                        sr = actual_sample_rate
                    # ä½¿ç”¨æ£€æµ‹åˆ°çš„é‡‡æ ·ç‡è®¡ç®—æ—¶é•¿ï¼ˆæ­¤æ—¶ sr åº”è¯¥ç­‰äº actual_sample_rateï¼‰
                    actual_audio_duration = len(audio_data) / actual_sample_rate
                    
                    # æ·»åŠ éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
                    self.logger.info(f"  å®é™…éŸ³é¢‘æ—¶é•¿: {actual_audio_duration:.3f}s")
                    self.logger.info(f"  åˆ†æ®µç›®æ ‡æ—¶é•¿: {end_time - start_time:.3f}s")
                    self.logger.info(f"  æ—¶é•¿å·®å¼‚: {actual_audio_duration - (end_time - start_time):+.3f}s")
                    
                    # è®¡ç®—æ’å…¥ä½ç½®å’Œæ—¶é—´çª—å£ï¼ˆä½¿ç”¨æ£€æµ‹åˆ°çš„é‡‡æ ·ç‡ï¼‰
                    start_sample = int(start_time * actual_sample_rate)
                    
                    # ä½¿ç”¨å®é™…éŸ³é¢‘æ—¶é•¿è€Œä¸æ˜¯åŸå§‹åˆ†æ®µæ—¶é—´æˆ³
                    actual_audio_duration_samples = len(audio_data)
                    end_sample = start_sample + actual_audio_duration_samples
                    target_duration_samples = actual_audio_duration_samples
                    
                    # æ·»åŠ æ—¶é—´çª—å£ä¿¡æ¯
                    self.logger.info(f"  æ—¶é—´çª—å£: {start_sample} - {end_sample} æ ·æœ¬")
                    self.logger.info(f"  ç›®æ ‡æ—¶é•¿æ ·æœ¬æ•°: {target_duration_samples}")
                    self.logger.info(f"  å®é™…éŸ³é¢‘æ ·æœ¬æ•°: {len(audio_data)}")
                    
                    # ç¡®ä¿ä¸è¶…å‡ºæ€»æ—¶é•¿è¾¹ç•Œ
                    if end_sample > total_samples:
                        end_sample = total_samples
                        actual_audio_duration_samples = end_sample - start_sample
                        padded_audio = audio_data[:actual_audio_duration_samples]
                        self.logger.warning(f"  âš ï¸ åˆ†æ®µè¶…å‡ºæ€»æ—¶é•¿ï¼Œè£å‰ªåˆ°: {actual_audio_duration_samples/actual_sample_rate:.3f}s")
                    else:
                        # ç›´æ¥ä½¿ç”¨å®é™…éŸ³é¢‘ï¼Œä¸éœ€è¦å¡«å……æˆ–æ‰©å±•
                        padded_audio = audio_data
                        self.logger.info(f"  âœ… ç›´æ¥ä½¿ç”¨å®é™…éŸ³é¢‘: {len(audio_data)/actual_sample_rate:.3f}s")
                    
                    # å¯¹æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µåº”ç”¨æœ«å°¾æ·¡å‡ºï¼Œæ¶ˆé™¤æ•°å­—ä¼ªå½±ï¼ˆé¢å¤–ä¿æŠ¤ï¼‰
                    fade_out_duration = 0.02  # 20msæ·¡å‡º
                    fade_out_samples = int(fade_out_duration * actual_sample_rate)
                    if len(padded_audio) > fade_out_samples:
                        fade_out_start = len(padded_audio) - fade_out_samples
                        fade_curve = np.linspace(1.0, 0.0, fade_out_samples)
                        padded_audio[fade_out_start:] *= fade_curve
                        self.logger.info(f"  âœ… å·²åº”ç”¨æœ«å°¾æ·¡å‡º: {fade_out_duration*1000:.0f}ms")
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ä¹‹å‰çš„éŸ³é¢‘é‡å 
                    if start_sample < len(audio_track):
                        existing_audio = audio_track[start_sample:end_sample]
                        has_existing = np.any(np.abs(existing_audio) > 1e-6)
                        
                        if has_existing:
                            # å­˜åœ¨é‡å ï¼Œä½¿ç”¨å…¨å±€ä¼˜åŒ–ç­–ç•¥
                            self.logger.warning(f"  âš ï¸ æ£€æµ‹åˆ°éŸ³é¢‘é‡å ï¼Œä½¿ç”¨å…¨å±€ä¼˜åŒ–ç­–ç•¥")
                            
                            # è®¡ç®—é‡å æ—¶é•¿ï¼ˆä½¿ç”¨æ£€æµ‹åˆ°çš„é‡‡æ ·ç‡ï¼‰
                            overlap_duration = (start_sample - len(audio_track)) / actual_sample_rate if start_sample < len(audio_track) else 0
                            
                            if overlap_duration > 0:
                                # å…¨å±€ä¼˜åŒ–ç­–ç•¥ï¼šæœ€å°åŒ–è°ƒæ•´è·ç¦»å’Œè°ƒæ•´æ•°é‡
                                adjustment_success = False
                                
                                # è®¡ç®—å½“å‰åˆ†æ®µçš„åŸå§‹èµ·å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—åå·®ï¼‰
                                current_segment_start_time = start_time
                                
                                # æ–¹æ¡ˆ1ï¼šå°è¯•æœ€å°åŒ–å½“å‰åˆ†æ®µçš„ç§»åŠ¨è·ç¦»
                                # å‘å‰ç§»åŠ¨ï¼šä¿æŒä¸åŸå§‹èµ·å§‹ç‚¹æœ€è¿‘
                                if start_sample > 0:
                                    # è®¡ç®—æœ€å°å¿…è¦ç§»åŠ¨è·ç¦»ï¼ˆåˆšå¥½æ¶ˆé™¤é‡å ï¼‰
                                    min_shift = overlap_duration * actual_sample_rate * 1.1  # å¤šç§»åŠ¨10%ç¡®ä¿å®‰å…¨
                                    optimal_shift = min(min_shift, start_sample)
                                    new_start_sample = max(0, start_sample - int(optimal_shift))
                                    new_end_sample = new_start_sample + len(padded_audio)
                                    
                                    # æ£€æŸ¥æ–°ä½ç½®æ˜¯å¦å®‰å…¨ä¸”ä¸ä¼šå½±å“å…¶ä»–åˆ†æ®µ
                                    if (new_start_sample < len(audio_track) and 
                                        new_end_sample <= total_samples and
                                        self._is_position_safe(audio_track, new_start_sample, new_end_sample)):
                                        
                                        # è®¡ç®—ç§»åŠ¨åçš„æ—¶é—´åå·®
                                        new_start_time = new_start_sample / actual_sample_rate
                                        time_deviation = abs(new_start_time - current_segment_start_time)
                                        
                                        # å¦‚æœåå·®åœ¨å¯æ¥å—èŒƒå›´å†…ï¼ˆæ¯”å¦‚0.5ç§’ï¼‰ï¼Œä½¿ç”¨æ–°ä½ç½®
                                        if time_deviation <= 0.5:
                                            audio_track[new_start_sample:new_end_sample] = padded_audio
                                            self.logger.info(f"  âœ… å…¨å±€ä¼˜åŒ–æˆåŠŸ: å‘å‰ç§»åŠ¨ {optimal_shift/actual_sample_rate:.3f}sï¼Œæ—¶é—´åå·® {time_deviation:.3f}sï¼Œæ–°ä½ç½® {new_start_sample}-{new_end_sample}")
                                            adjustment_success = True
                                
                                # æ–¹æ¡ˆ2ï¼šå¦‚æœå‘å‰ç§»åŠ¨åå·®å¤ªå¤§ï¼Œå°è¯•å‘åç§»åŠ¨
                                if not adjustment_success and end_sample < total_samples:
                                    # è®¡ç®—æœ€å°å¿…è¦ç§»åŠ¨è·ç¦»
                                    min_shift = overlap_duration * actual_sample_rate * 1.1
                                    new_start_sample = start_sample + int(min_shift)
                                    new_end_sample = new_start_sample + len(padded_audio)
                                    
                                    # æ£€æŸ¥æ–°ä½ç½®æ˜¯å¦å®‰å…¨
                                    if (new_end_sample <= total_samples and
                                        self._is_position_safe(audio_track, new_start_sample, new_end_sample)):
                                        
                                        # è®¡ç®—ç§»åŠ¨åçš„æ—¶é—´åå·®
                                        new_start_time = new_start_sample / actual_sample_rate
                                        time_deviation = abs(new_start_time - current_segment_start_time)
                                        
                                        # å¦‚æœåå·®åœ¨å¯æ¥å—èŒƒå›´å†…ï¼Œä½¿ç”¨æ–°ä½ç½®
                                        if time_deviation <= 0.5:
                                            audio_track[new_start_sample:new_end_sample] = padded_audio
                                            self.logger.info(f"  âœ… å…¨å±€ä¼˜åŒ–æˆåŠŸ: å‘åç§»åŠ¨ {min_shift/actual_sample_rate:.3f}sï¼Œæ—¶é—´åå·® {time_deviation:.3f}sï¼Œæ–°ä½ç½® {new_start_sample}-{new_end_sample}")
                                            adjustment_success = True
                                
                                # æ–¹æ¡ˆ3ï¼šå¦‚æœå…¨å±€ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨éŸ³é¢‘æ··åˆ
                                if not adjustment_success:
                                    mixed_audio = (audio_track[start_sample:end_sample] + padded_audio) * 0.5
                                    audio_track[start_sample:end_sample] = mixed_audio
                                    self.logger.info(f"  âœ… å…¨å±€ä¼˜åŒ–å¤±è´¥ï¼Œä½¿ç”¨éŸ³é¢‘æ··åˆ: ä½ç½® {start_sample}-{end_sample}")
                            else:
                                # æ²¡æœ‰é‡å æ—¶é•¿ï¼Œç›´æ¥æ··åˆ
                                mixed_audio = (audio_track[start_sample:end_sample] + padded_audio) * 0.5
                                audio_track[start_sample:end_sample] = mixed_audio
                                self.logger.info(f"  âœ… éŸ³é¢‘æ··åˆæˆåŠŸ: ä½ç½® {start_sample}-{end_sample}")
                        else:
                            # æ²¡æœ‰é‡å ï¼Œç›´æ¥æ’å…¥
                            audio_track[start_sample:end_sample] = padded_audio
                            self.logger.info(f"  âœ… éŸ³é¢‘æ’å…¥æˆåŠŸ: ä½ç½® {start_sample}-{end_sample}")
                    else:
                        # è¶…å‡ºæ€»æ—¶é•¿ï¼Œç›´æ¥æ’å…¥
                        if end_sample <= total_samples:
                            audio_track[start_sample:end_sample] = padded_audio
                            self.logger.info(f"  âœ… éŸ³é¢‘æ’å…¥æˆåŠŸ: ä½ç½® {start_sample}-{end_sample}")
                        else:
                            self.logger.warning(f"  âŒ å¼€å§‹ä½ç½®è¶…å‡ºæ€»æ—¶é•¿: {start_sample} >= {total_samples}")
                            continue
                    
                    segments_processed += 1
                        
                except Exception as e:
                    self.logger.warning(f"å¤„ç†ç‰‡æ®µ {i} å¤±è´¥: {e}")
                    continue
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ï¼Œå¦‚æœå­˜åœ¨åˆ™åˆå¹¶
            # ä½¿ç”¨æ–°çš„æ ‡å‡†åŒ–å‘½åè§„åˆ™
            output_dir = os.path.dirname(output_path)
            accompaniment_path = os.path.join(output_dir, "02_accompaniment.wav")
            if os.path.exists(accompaniment_path):
                self.logger.info(f"ğŸµ å‘ç°èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ï¼Œå¼€å§‹åˆå¹¶: {accompaniment_path}")
                try:
                    # åŠ è½½èƒŒæ™¯éŸ³ä¹ï¼ˆä½¿ç”¨æ£€æµ‹åˆ°çš„é‡‡æ ·ç‡ï¼‰
                    accompaniment_data, accomp_sr = librosa.load(accompaniment_path, sr=None)
                    
                    # å¦‚æœé‡‡æ ·ç‡ä¸ä¸€è‡´ï¼Œé‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡ï¼ˆä½¿ç”¨é«˜è´¨é‡é‡é‡‡æ ·ç®—æ³•ï¼‰
                    if accomp_sr != actual_sample_rate:
                        if accomp_sr < actual_sample_rate:
                            self.logger.info(f"  ğŸ”„ èƒŒæ™¯éŸ³ä¹é‡‡æ ·ç‡ä¸åŒ¹é… ({accomp_sr} Hz < {actual_sample_rate} Hz)ï¼Œå‡é‡‡æ ·åˆ° {actual_sample_rate} Hzï¼ˆä½¿ç”¨kaiser_bestç®—æ³•ï¼‰")
                        else:
                            self.logger.info(f"  ğŸ”„ èƒŒæ™¯éŸ³ä¹é‡‡æ ·ç‡ä¸åŒ¹é… ({accomp_sr} Hz > {actual_sample_rate} Hz)ï¼Œé™é‡‡æ ·åˆ° {actual_sample_rate} Hzï¼ˆä½¿ç”¨kaiser_bestç®—æ³•ï¼‰")
                        accompaniment_data = librosa.resample(accompaniment_data, orig_sr=accomp_sr, target_sr=actual_sample_rate, res_type='kaiser_best')
                        accomp_sr = actual_sample_rate
                    
                    # è°ƒæ•´èƒŒæ™¯éŸ³ä¹é•¿åº¦ä»¥åŒ¹é…è¯­éŸ³è½¨é“
                    if len(accompaniment_data) < len(audio_track):
                        # èƒŒæ™¯éŸ³ä¹è¾ƒçŸ­ï¼Œå¡«å……é™éŸ³
                        padding = np.zeros(len(audio_track) - len(accompaniment_data))
                        accompaniment_data = np.concatenate([accompaniment_data, padding])
                    elif len(accompaniment_data) > len(audio_track):
                        # èƒŒæ™¯éŸ³ä¹è¾ƒé•¿ï¼Œè£å‰ª
                        accompaniment_data = accompaniment_data[:len(audio_track)]
                    
                    # åˆ†æåŸå§‹éŸ³é¢‘ä¸­èƒŒæ™¯éŸ³ä¹å’Œäººå£°çš„ç›¸å¯¹æ¯”ä¾‹
                    original_voice_rms, original_accomp_rms = self._analyze_original_audio_ratio(output_dir, actual_sample_rate)
                    
                    # ä¼˜åŒ–å¤„ç†é¡ºåºï¼šå…ˆè¿›è¡ŒéŸ³é‡å¹³è¡¡ï¼Œå†è¿›è¡Œæ··åˆï¼Œæœ€åç»Ÿä¸€è¿›è¡ŒéŸ³é‡æ ‡å‡†åŒ–
                    # åˆå¹¶è¯­éŸ³å’ŒèƒŒæ™¯éŸ³ä¹ï¼Œå¹¶è¿›è¡ŒéŸ³é‡å¹³è¡¡ï¼ˆä¿æŒåŸå§‹æ¯”ä¾‹ï¼‰
                    final_audio = self._balance_audio_levels(audio_track, accompaniment_data, 
                                                             original_voice_rms, original_accomp_rms)
                    self.logger.info("âœ… èƒŒæ™¯éŸ³ä¹åˆå¹¶æˆåŠŸ")
                    
                    # éŸ³é‡æ ‡å‡†åŒ–ï¼ˆæœ€åç»Ÿä¸€è¿›è¡Œï¼‰
                    final_audio_normalized = self._normalize_audio_volume(final_audio)
                    
                    # ä¿å­˜åˆå¹¶åçš„éŸ³é¢‘ï¼ˆä½¿ç”¨æ£€æµ‹åˆ°çš„é‡‡æ ·ç‡ï¼‰
                    # soundfileä¼šè‡ªåŠ¨å°†float32è½¬æ¢ä¸ºPCM_16ï¼Œå¹¶ä½¿ç”¨é«˜è´¨é‡ditheringå‡å°‘é‡åŒ–è¯¯å·®
                    # ä½¿ç”¨PCM_16æ ¼å¼ï¼ˆæœ€é€šç”¨ï¼Œsoundfileä¼šè‡ªåŠ¨è¿›è¡Œé«˜è´¨é‡è½¬æ¢ï¼‰
                    sf.write(output_path, final_audio_normalized, actual_sample_rate, subtype='PCM_16')
                except Exception as e:
                    self.logger.warning(f"èƒŒæ™¯éŸ³ä¹åˆå¹¶å¤±è´¥: {e}ï¼Œä»…ä¿å­˜è¯­éŸ³")
                    # å¦‚æœåˆå¹¶å¤±è´¥ï¼Œå…ˆè¿›è¡ŒéŸ³é‡æ ‡å‡†åŒ–ï¼Œç„¶åä¿å­˜åŸå§‹è¯­éŸ³ï¼ˆä½¿ç”¨æ£€æµ‹åˆ°çš„é‡‡æ ·ç‡ï¼‰
                    audio_track_normalized = self._normalize_audio_volume(audio_track)
                    sf.write(output_path, audio_track_normalized, actual_sample_rate, subtype='PCM_16')
            else:
                self.logger.info("âš ï¸  æœªæ‰¾åˆ°èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ï¼Œä»…ä¿å­˜è¯­éŸ³")
                # ä¼˜åŒ–å¤„ç†é¡ºåºï¼šæœ€åç»Ÿä¸€è¿›è¡ŒéŸ³é‡æ ‡å‡†åŒ–
                final_audio_normalized = self._normalize_audio_volume(audio_track)
                # ä¿å­˜æœ€ç»ˆéŸ³é¢‘ï¼ˆä½¿ç”¨æ£€æµ‹åˆ°çš„é‡‡æ ·ç‡ï¼‰
                # soundfileä¼šè‡ªåŠ¨å°†float32è½¬æ¢ä¸ºPCM_16ï¼Œå¹¶ä½¿ç”¨é«˜è´¨é‡ditheringå‡å°‘é‡åŒ–è¯¯å·®
                sf.write(output_path, final_audio_normalized, actual_sample_rate, subtype='PCM_16')
            
            # æ¸…ç†ä¸´æ—¶ç›®å½•
            import shutil
            shutil.rmtree(temp_dir)
            
            return {
                "success": True,
                "output_path": output_path,
                "segments_processed": segments_processed,
                "total_duration": total_duration,
                "method": "librosa"
            }
            
        except Exception as e:
            self.logger.error(f"librosaæ–¹æ³•å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e),
                "method": "librosa"
            }
    
    def _create_silent_audio(self, duration: float, output_path: str):
        """
        åˆ›å»ºé™éŸ³éŸ³é¢‘æ–‡ä»¶
        
        Args:
            duration: æ—¶é•¿ï¼ˆç§’ï¼‰
            output_path: è¾“å‡ºè·¯å¾„
        """
        cmd = [
            'ffmpeg',
            '-f', 'lavfi',
            '-i', f'anullsrc=channel_layout=stereo:sample_rate={self.sample_rate}',
            '-t', str(duration),
            '-y',
            output_path
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            raise Exception(f"åˆ›å»ºé™éŸ³éŸ³é¢‘å¤±è´¥: {result.stderr}")
    
    def _add_delay_to_audio(self, input_audio: str, delay_seconds: float, output_audio: str):
        """
        ä¸ºéŸ³é¢‘æ·»åŠ å»¶è¿Ÿ
        
        Args:
            input_audio: è¾“å…¥éŸ³é¢‘æ–‡ä»¶
            delay_seconds: å»¶è¿Ÿç§’æ•°
            output_audio: è¾“å‡ºéŸ³é¢‘æ–‡ä»¶
        """
        if delay_seconds <= 0:
            # ä¸éœ€è¦å»¶è¿Ÿï¼Œç›´æ¥å¤åˆ¶
            import shutil
            shutil.copy2(input_audio, output_audio)
            return
        
        cmd = [
            'ffmpeg',
            '-i', input_audio,
            '-af', f'adelay={int(delay_seconds * 1000)}',
            '-y',
            output_audio
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            raise Exception(f"æ·»åŠ å»¶è¿Ÿå¤±è´¥: {result.stderr}")
    
    def _is_position_safe(self, audio_track: np.ndarray, start_sample: int, end_sample: int) -> bool:
        """
        æ£€æŸ¥æŒ‡å®šä½ç½®æ˜¯å¦å®‰å…¨ï¼ˆæ²¡æœ‰ä¸å…¶ä»–éŸ³é¢‘é‡å ï¼‰
        
        Args:
            audio_track: éŸ³é¢‘è½¨é“
            start_sample: å¼€å§‹æ ·æœ¬ä½ç½®
            end_sample: ç»“æŸæ ·æœ¬ä½ç½®
            
        Returns:
            æ˜¯å¦å®‰å…¨
        """
        try:
            # æ£€æŸ¥è¾¹ç•Œ
            if start_sample < 0 or end_sample > len(audio_track):
                return False
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç°æœ‰éŸ³é¢‘
            existing_audio = audio_track[start_sample:end_sample]
            has_existing = np.any(np.abs(existing_audio) > 1e-6)
            
            return not has_existing
        except Exception:
            return False
    
    def _merge_audio_files(self, audio_files: List[str], output_path: str):
        """
        åˆå¹¶å¤šä¸ªéŸ³é¢‘æ–‡ä»¶ï¼ˆæ—¶é—´åŒæ­¥æ··åˆï¼‰
        
        Args:
            audio_files: éŸ³é¢‘æ–‡ä»¶åˆ—è¡¨ [é™éŸ³è½¨é“, åˆ†æ®µ1, åˆ†æ®µ2, ...]
            output_path: è¾“å‡ºè·¯å¾„
        """
        if len(audio_files) == 1:
            # åªæœ‰ä¸€ä¸ªæ–‡ä»¶ï¼Œç›´æ¥å¤åˆ¶
            import shutil
            shutil.copy2(audio_files[0], output_path)
            return
        
        # åˆ†æåŸå§‹å‚è€ƒéŸ³é¢‘çš„éŸ³é‡ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªéé™éŸ³æ–‡ä»¶ä½œä¸ºå‚è€ƒï¼‰
        reference_volume = self._analyze_audio_volume(audio_files[1]) if len(audio_files) > 1 else -11.0
        self.logger.info(f"å‚è€ƒéŸ³é¢‘éŸ³é‡: {reference_volume:.2f} dB")
        
        # åŸºäºè§‚å¯Ÿï¼ŒåˆæˆéŸ³é¢‘çš„å…¸å‹éŸ³é‡çº¦ä¸º-24.5dBï¼Œéœ€è¦è°ƒæ•´åˆ°ä¸å‚è€ƒéŸ³é¢‘ç›¸åŒ
        # è®¡ç®—éŸ³é‡è°ƒæ•´å€¼ï¼Œè®©è¾“å‡ºéŸ³é¢‘ä¸å‚è€ƒéŸ³é¢‘éŸ³é‡æ¥è¿‘
        # é¢å¤–å¢åŠ 3dBå¢ç›Šï¼Œè®©äººå£°éŸ³é‡æ›´æ˜æ˜¾
        voice_gain_db = 3.0  # é¢å¤–å¢åŠ 3dBéŸ³é‡
        target_volume = reference_volume + voice_gain_db  # ç›®æ ‡éŸ³é‡æ¯”å‚è€ƒéŸ³é¢‘å¤§3dB
        current_volume = -24.5  # åˆæˆéŸ³é¢‘çš„å…¸å‹éŸ³é‡ï¼ˆåŸºäºè§‚å¯Ÿï¼‰
        volume_adjustment = target_volume - current_volume
        self.logger.info(f"éŸ³é‡è°ƒæ•´è®¡ç®—: ç›®æ ‡={target_volume:.2f}dB (å‚è€ƒ={reference_volume:.2f}dB + å¢ç›Š={voice_gain_db}dB), å½“å‰={current_volume:.2f}dB, è°ƒæ•´={volume_adjustment:.2f}dB")
        
        # æ„å»ºFFmpegå‘½ä»¤ï¼Œä½¿ç”¨amixè¿›è¡Œæ—¶é—´åŒæ­¥æ··åˆ
        cmd = ['ffmpeg']
        
        # æ·»åŠ æ‰€æœ‰è¾“å…¥æ–‡ä»¶
        for audio_file in audio_files:
            cmd.extend(['-i', audio_file])
        
        # æ„å»ºamixæ»¤é•œï¼Œæ·»åŠ éŸ³é‡æ ‡å‡†åŒ–
        # ç¬¬ä¸€ä¸ªè¾“å…¥æ˜¯é™éŸ³è½¨é“ï¼Œåç»­æ˜¯å„ä¸ªåˆ†æ®µ
        amix_inputs = len(audio_files)
        
        # ä½¿ç”¨æ›´ç®€å•çš„éŸ³é‡åŒ¹é…æ–¹æ³•
        # å…ˆåˆ†æå‚è€ƒéŸ³é¢‘éŸ³é‡ï¼Œç„¶åè°ƒæ•´å…¶ä»–éŸ³é¢‘
        if amix_inputs > 1:
            # æ„å»ºéŸ³é‡åŒ¹é…æ»¤é•œ
            filter_parts = []
            
            # ä¸ºæ¯ä¸ªéŸ³é¢‘è¾“å…¥æ·»åŠ éŸ³é‡è°ƒæ•´ï¼ˆè·³è¿‡é™éŸ³è½¨é“ï¼‰
            for i in range(1, amix_inputs):
                # ä½¿ç”¨volumeæ»¤é•œè¿›è¡ŒéŸ³é‡è°ƒæ•´
                filter_parts.append(f"[{i}]volume={volume_adjustment}dB[{i}_vol]")
            
            # æ„å»ºamixè¾“å…¥
            amix_inputs_list = ["[0]"]  # é™éŸ³è½¨é“
            for i in range(1, amix_inputs):
                amix_inputs_list.append(f"[{i}_vol]")
            
            # FFmpeg 4.2.7ä¸æ”¯æŒnormalizeå‚æ•°ï¼Œä½¿ç”¨weightsæ¥ä¿æŒéŸ³é‡
            # ç»™æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µç›¸åŒçš„æƒé‡ï¼Œé¿å…éŸ³é‡é™ä½
            weights = " ".join(["1"] * amix_inputs)
            filter_complex = f"{';'.join(filter_parts)};{''.join(amix_inputs_list)}amix=inputs={amix_inputs}:duration=longest:weights=\"{weights}\""
        else:
            filter_complex = f"amix=inputs={amix_inputs}:duration=longest"
        
        cmd.extend([
            '-filter_complex', filter_complex,
            '-y',
            output_path
        ])
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode != 0:
            raise Exception(f"åˆå¹¶éŸ³é¢‘å¤±è´¥: {result.stderr}")
        
        # éªŒè¯è¾“å‡ºéŸ³é¢‘éŸ³é‡
        output_volume = self._analyze_audio_volume(output_path)
        self.logger.info(f"è¾“å‡ºéŸ³é¢‘éŸ³é‡: {output_volume:.2f} dB")
    
    def _analyze_audio_volume(self, audio_path: str) -> float:
        """
        åˆ†æéŸ³é¢‘æ–‡ä»¶çš„éŸ³é‡ï¼ˆRMSï¼‰
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            éŸ³é‡å€¼ï¼ˆdBï¼‰
        """
        try:
            # ä½¿ç”¨FFmpegåˆ†æéŸ³é¢‘éŸ³é‡
            cmd = [
                'ffmpeg',
                '-i', audio_path,
                '-af', 'volumedetect',
                '-f', 'null',
                '-'
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            
            # è§£æFFmpegè¾“å‡ºä¸­çš„éŸ³é‡ä¿¡æ¯
            lines = result.stderr.split('\n')
            for line in lines:
                if 'mean_volume:' in line:
                    # æå–éŸ³é‡å€¼ï¼Œæ ¼å¼å¦‚ï¼šmean_volume: -20.5 dB
                    parts = line.split('mean_volume:')
                    if len(parts) > 1:
                        volume_str = parts[1].strip().split()[0]
                        return float(volume_str)
            
            # å¦‚æœæ— æ³•è§£æï¼Œè¿”å›é»˜è®¤å€¼
            self.logger.warning(f"æ— æ³•è§£æéŸ³é¢‘éŸ³é‡: {audio_path}")
            return -20.0
            
        except Exception as e:
            self.logger.error(f"åˆ†æéŸ³é¢‘éŸ³é‡å¤±è´¥: {e}")
            return -20.0
    
    def get_original_audio_duration(self, audio_path: str) -> float:
        """
        è·å–åŸå§‹éŸ³é¢‘çš„æ—¶é•¿
        
        Args:
            audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„
            
        Returns:
            éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        """
        try:
            cmd = [
                'ffprobe',
                '-v', 'quiet',
                '-show_entries', 'format=duration',
                '-of', 'csv=p=0',
                audio_path
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode == 0:
                return float(result.stdout.strip())
            else:
                raise Exception(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {result.stderr}")
                
        except Exception as e:
            self.logger.error(f"è·å–éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
            return 0.0
    
    def _adjust_audio_duration_if_needed(self, audio_path: str, target_duration: float, output_path: str) -> bool:
        """
        å¦‚æœç¿»è¯‘åéŸ³é¢‘æ—¶é•¿å¤§äºç›®æ ‡æ—¶é•¿ï¼Œå‹ç¼©è‡³ç›®æ ‡æ—¶é•¿
        å¦‚æœå°äºæˆ–ç­‰äºï¼Œä¿æŒä¸å˜
        æ·»åŠ å‹ç¼©æ¯”ä¾‹é™åˆ¶ï¼Œé¿å…è¯­é€Ÿè¿‡å¿«
        """
        try:
            # è·å–éŸ³é¢‘å®é™…æ—¶é•¿
            actual_duration = self.get_original_audio_duration(audio_path)
            
            # æ·»åŠ è¯¦ç»†è°ƒè¯•ä¿¡æ¯
            self.logger.info(f"ğŸ” éŸ³é¢‘æ—¶é•¿è°ƒæ•´åˆ†æ:")
            self.logger.info(f"  éŸ³é¢‘æ–‡ä»¶: {audio_path}")
            self.logger.info(f"  å®é™…æ—¶é•¿: {actual_duration:.3f}s")
            self.logger.info(f"  ç›®æ ‡æ—¶é•¿: {target_duration:.3f}s")
            self.logger.info(f"  æ—¶é•¿å·®å¼‚: {actual_duration - target_duration:+.3f}s")
            
            if actual_duration <= 0:
                self.logger.warning(f"æ— æ³•è·å–éŸ³é¢‘æ—¶é•¿: {audio_path}")
                return False
            
            # å¦‚æœå®é™…æ—¶é•¿ <= ç›®æ ‡æ—¶é•¿ï¼Œåº”ç”¨æ·¡å‡ºæ•ˆæœåå¤åˆ¶ï¼ˆæ¶ˆé™¤æ•°å­—ä¼ªå½±ï¼‰
            if actual_duration <= target_duration:
                # å¯¹æ‰€æœ‰éŸ³é¢‘éƒ½åº”ç”¨æœ«å°¾æ·¡å‡ºï¼Œæ¶ˆé™¤æ•°å­—ä¼ªå½±
                fade_out_duration = 0.02  # 20msæ·¡å‡º
                fade_start_time = max(0, actual_duration - fade_out_duration)
                
                # ä½¿ç”¨FFmpegæ·»åŠ æ·¡å‡ºæ•ˆæœ
                import tempfile
                temp_dir = tempfile.mkdtemp()
                try:
                    final_output = os.path.join(temp_dir, "final_with_fade.wav")
                    cmd_fade = [
                        'ffmpeg',
                        '-i', audio_path,
                        '-af', f'afade=t=out:st={fade_start_time:.3f}:d={fade_out_duration:.3f}',
                        '-y', final_output
                    ]
                    
                    result_fade = subprocess.run(cmd_fade, capture_output=True, text=True)
                    
                    if result_fade.returncode == 0:
                        import shutil
                        shutil.copy2(final_output, output_path)
                        self.logger.info(f"éŸ³é¢‘æ—¶é•¿åˆé€‚ ({actual_duration:.2f}s <= {target_duration:.2f}s)ï¼Œå·²åº”ç”¨æœ«å°¾æ·¡å‡º: {fade_out_duration*1000:.0f}ms")
                    else:
                        # å¦‚æœæ·¡å‡ºå¤„ç†å¤±è´¥ï¼Œç›´æ¥å¤åˆ¶ï¼ˆé™çº§å¤„ç†ï¼‰
                        self.logger.warning(f"æ·¡å‡ºå¤„ç†å¤±è´¥ï¼Œç›´æ¥å¤åˆ¶: {result_fade.stderr}")
                        import shutil
                        shutil.copy2(audio_path, output_path)
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    import shutil
                    shutil.rmtree(temp_dir)
                    return True
                except Exception as e:
                    self.logger.warning(f"æ·¡å‡ºå¤„ç†å¼‚å¸¸ï¼Œç›´æ¥å¤åˆ¶: {e}")
                    import shutil
                    if os.path.exists(temp_dir):
                        shutil.rmtree(temp_dir)
                    # é™çº§å¤„ç†ï¼šç›´æ¥å¤åˆ¶
                    import shutil
                    shutil.copy2(audio_path, output_path)
                    return True
            
            # å¦‚æœå®é™…æ—¶é•¿ > ç›®æ ‡æ—¶é•¿ï¼Œè¿›è¡Œæ—¶é—´å‹ç¼©
            # è®©å€é€Ÿæ¯”è®¡ç®—å¾—åˆ°çš„å€é€Ÿå¤§ä¸€ç‚¹ï¼Œç¡®ä¿ä¸è¶…å‡ºåˆ†æ®µæ—¶é—´æˆ³
            speed_ratio = actual_duration / target_duration  # åŸºç¡€å€é€Ÿ
            enhanced_speed_ratio = speed_ratio * 1.10  # å¢åŠ 10%ç¡®ä¿ä¸è¶…å‡º
            self.logger.info(f"éŸ³é¢‘è¿‡é•¿ ({actual_duration:.2f}s > {target_duration:.2f}s)ï¼ŒåŸºç¡€å€é€Ÿ {speed_ratio:.2f}ï¼Œå¢å¼ºå€é€Ÿ {enhanced_speed_ratio:.2f}")
            
            # ä¸¥æ ¼é™åˆ¶å€é€Ÿä¸è¶…è¿‡2.0
            if enhanced_speed_ratio > self.max_speed_ratio:
                # å€é€Ÿè¶…è¿‡é™åˆ¶ï¼Œä½¿ç”¨æœ€å¤§å…è®¸å€é€Ÿ
                self.logger.warning(f"å€é€Ÿè¿‡å¿« ({enhanced_speed_ratio:.2f} > {self.max_speed_ratio:.2f} å€é€Ÿ)ï¼Œé™åˆ¶ä¸ºæœ€å¤§å€é€Ÿ {self.max_speed_ratio:.2f}")
                final_speed_ratio = self.max_speed_ratio
            else:
                # ä½¿ç”¨å¢å¼ºå€é€Ÿ
                final_speed_ratio = enhanced_speed_ratio
                self.logger.info(f"ä½¿ç”¨å¢å¼ºå€é€Ÿ {enhanced_speed_ratio:.2f}ï¼Œç¡®ä¿ä¸è¶…å‡ºåˆ†æ®µæ—¶é—´æˆ³")
            
            # è¿›è¡Œæ—¶é—´å‹ç¼©ï¼ˆä¸¥æ ¼é™åˆ¶åœ¨2.0å€é€Ÿä»¥å†…ï¼‰
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶è¿›è¡Œå¤šæ­¥å¤„ç†
            import tempfile
            temp_dir = tempfile.mkdtemp()
            temp_file = os.path.join(temp_dir, "temp_speed.wav")
            
            try:
                # å¯¹äºå€é€Ÿè¶…è¿‡1.2çš„æƒ…å†µï¼Œåˆ†ä¸¤æ­¥å¤„ç†ä»¥å‡å°‘å¤±çœŸ
                speed_processed_file = temp_file
                
                if final_speed_ratio > 1.2:
                    # ç¬¬ä¸€æ­¥ï¼šä½¿ç”¨è¾ƒä½çš„å€é€Ÿï¼ˆ1.2ï¼‰å¤„ç†
                    first_speed = 1.2
                    remaining_ratio = final_speed_ratio / first_speed
                    
                    self.logger.info(f"åˆ†æ­¥å€é€Ÿå¤„ç†ï¼šç¬¬ä¸€æ­¥ {first_speed:.2f}xï¼Œå‰©ä½™ {remaining_ratio:.2f}x")
                    
                    # ç¬¬ä¸€æ­¥å¤„ç†
                    cmd1 = [
                        'ffmpeg',
                        '-i', audio_path,
                        '-af', f'atempo={first_speed}',
                        '-y', temp_file
                    ]
                    result1 = subprocess.run(cmd1, capture_output=True, text=True)
                    
                    if result1.returncode != 0:
                        self.logger.error(f"ç¬¬ä¸€æ­¥å€é€Ÿå¤„ç†å¤±è´¥: {result1.stderr}")
                        return False
                    
                    # ç¬¬äºŒæ­¥ï¼šå¯¹å‰©ä½™å€é€Ÿè¿›è¡Œå¤„ç†
                    if remaining_ratio > 1.0:
                        temp_file2 = os.path.join(temp_dir, "temp_speed2.wav")
                        cmd2 = [
                            'ffmpeg',
                            '-i', temp_file,
                            '-af', f'atempo={remaining_ratio}',
                            '-y', temp_file2
                        ]
                        result2 = subprocess.run(cmd2, capture_output=True, text=True)
                        
                        if result2.returncode != 0:
                            self.logger.error(f"ç¬¬äºŒæ­¥å€é€Ÿå¤„ç†å¤±è´¥: {result2.stderr}")
                            return False
                        
                        speed_processed_file = temp_file2
                    else:
                        # å¦‚æœå‰©ä½™å€é€Ÿ<=1ï¼Œç›´æ¥ä½¿ç”¨ç¬¬ä¸€æ­¥ç»“æœ
                        speed_processed_file = temp_file
                else:
                    # å€é€Ÿ<=1.2ï¼Œå•æ¬¡å¤„ç†
                    cmd = [
                        'ffmpeg',
                        '-i', audio_path,
                        '-af', f'atempo={final_speed_ratio}',
                        '-y', temp_file
                    ]
                    result = subprocess.run(cmd, capture_output=True, text=True)
                    
                    if result.returncode != 0:
                        self.logger.error(f"å€é€Ÿå¤„ç†å¤±è´¥: {result.stderr}")
                        return False
                    
                    speed_processed_file = temp_file
                
                # éªŒè¯å‹ç¼©åçš„æ—¶é•¿
                compressed_duration = self.get_original_audio_duration(speed_processed_file)
                
                # æ·»åŠ éŸ³é¢‘è´¨é‡æ£€æŸ¥ï¼šæ£€æµ‹æœ«å°¾å¼‚å¸¸å³°å€¼
                audio_data, sr = librosa.load(speed_processed_file, sr=None)
                if len(audio_data) > 0:
                    # æ£€æŸ¥éŸ³é¢‘æœ«å°¾æœ€å50msçš„å³°å€¼
                    tail_samples = int(0.05 * sr)  # 50ms
                    tail_samples = min(tail_samples, len(audio_data))
                    if tail_samples > 0:
                        tail_audio = audio_data[-tail_samples:]
                        tail_max_amplitude = np.max(np.abs(tail_audio))
                        
                        # å¦‚æœæœ«å°¾å³°å€¼è¶…è¿‡å¹³å‡å³°å€¼çš„3å€ï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜
                        overall_max = np.max(np.abs(audio_data))
                        if overall_max > 0:
                            tail_ratio = tail_max_amplitude / overall_max
                            if tail_ratio > 0.8:
                                self.logger.warning(f"æ£€æµ‹åˆ°éŸ³é¢‘æœ«å°¾å¯èƒ½å­˜åœ¨é—®é¢˜ï¼ˆå³°å€¼æ¯”: {tail_ratio:.2f}ï¼‰ï¼Œåº”ç”¨ä½é€šæ»¤æ³¢")
                                # åº”ç”¨ä½é€šæ»¤æ³¢å»é™¤é«˜é¢‘å™ªå£°
                                import scipy.signal
                                nyquist = sr / 2
                                cutoff = min(8000, nyquist * 0.9)  # 8kHzä½é€šæ»¤æ³¢
                                b, a = scipy.signal.butter(4, cutoff / nyquist, btype='low')
                                audio_data = scipy.signal.filtfilt(b, a, audio_data)
                                # ä¿å­˜æ»¤æ³¢åçš„éŸ³é¢‘
                                sf.write(speed_processed_file, audio_data, sr)
                                self.logger.info(f"ä½é€šæ»¤æ³¢å®Œæˆ: æˆªæ­¢é¢‘ç‡ {cutoff:.0f}Hz")
                
                # æ·»åŠ éŸ³é¢‘æœ«å°¾æ·¡å‡ºæ•ˆæœä»¥å‡å°‘æ•°å­—ä¼ªå½±
                fade_out_duration = 0.02  # 20msæ·¡å‡º
                fade_start_time = max(0, compressed_duration - fade_out_duration)
                
                # ä½¿ç”¨FFmpegæ·»åŠ æ·¡å‡ºæ•ˆæœ
                final_output = os.path.join(temp_dir, "final_with_fade.wav")
                cmd_fade = [
                    'ffmpeg',
                    '-i', speed_processed_file,
                    '-af', f'afade=t=out:st={fade_start_time:.3f}:d={fade_out_duration:.3f}',
                    '-y', final_output
                ]
                
                result_fade = subprocess.run(cmd_fade, capture_output=True, text=True)
                
                if result_fade.returncode == 0:
                    import shutil
                    shutil.copy2(final_output, output_path)
                    self.logger.info(f"éŸ³é¢‘æœ«å°¾æ·¡å‡ºå¤„ç†å®Œæˆ: {fade_out_duration*1000:.0f}ms")
                else:
                    # å¦‚æœæ·¡å‡ºå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å€é€Ÿå¤„ç†ç»“æœ
                    self.logger.warning(f"æ·¡å‡ºå¤„ç†å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹éŸ³é¢‘: {result_fade.stderr}")
                    import shutil
                    shutil.copy2(speed_processed_file, output_path)
                
                # æœ€ç»ˆéªŒè¯
                final_duration = self.get_original_audio_duration(output_path)
                self.logger.info(f"å€é€Ÿå¤„ç†ï¼š{actual_duration:.2f}s -> {target_duration:.2f}sï¼Œæœ€ç»ˆå€é€Ÿ {final_speed_ratio:.2f}")
                self.logger.info(f"éŸ³é¢‘æ—¶é•¿è°ƒæ•´æˆåŠŸ: {actual_duration:.2f}s -> {final_duration:.2f}s")
                
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                import shutil
                shutil.rmtree(temp_dir)
                
                return True
                
            except Exception as e:
                self.logger.error(f"å€é€Ÿå¤„ç†å¼‚å¸¸: {e}")
                # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                import shutil
                if os.path.exists(temp_dir):
                    shutil.rmtree(temp_dir)
                return False
                
        except Exception as e:
            self.logger.error(f"è°ƒæ•´éŸ³é¢‘æ—¶é•¿å¤±è´¥: {e}")
            return False
    
    def _analyze_original_audio_ratio(self, output_dir: str, target_sample_rate: int) -> tuple:
        """
        åˆ†æåŸå§‹éŸ³é¢‘ä¸­èƒŒæ™¯éŸ³ä¹å’Œäººå£°çš„ç›¸å¯¹æ¯”ä¾‹
        
        Args:
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            target_sample_rate: ç›®æ ‡é‡‡æ ·ç‡
            
        Returns:
            (åŸå§‹äººå£°RMS, åŸå§‹èƒŒæ™¯éŸ³ä¹RMS) çš„å…ƒç»„
        """
        try:
            # åŠ è½½åˆ†ç¦»åçš„äººå£°å’ŒèƒŒæ™¯éŸ³ä¹
            vocals_path = os.path.join(output_dir, "02_vocals.wav")
            accompaniment_path = os.path.join(output_dir, "02_accompaniment.wav")
            
            if os.path.exists(vocals_path) and os.path.exists(accompaniment_path):
                vocals, vocals_sr = librosa.load(vocals_path, sr=None)
                accompaniment, accomp_sr = librosa.load(accompaniment_path, sr=None)
                
                # ç»Ÿä¸€é‡‡æ ·ç‡
                if vocals_sr != target_sample_rate:
                    vocals = librosa.resample(vocals, orig_sr=vocals_sr, target_sr=target_sample_rate, res_type='kaiser_best')
                if accomp_sr != target_sample_rate:
                    accompaniment = librosa.resample(accompaniment, orig_sr=accomp_sr, target_sr=target_sample_rate, res_type='kaiser_best')
                
                # è°ƒæ•´é•¿åº¦ä»¥åŒ¹é…
                min_length = min(len(vocals), len(accompaniment))
                vocals = vocals[:min_length]
                accompaniment = accompaniment[:min_length]
                
                # è®¡ç®—RMS
                original_voice_rms = np.sqrt(np.mean(vocals**2))
                original_accomp_rms = np.sqrt(np.mean(accompaniment**2))
                
                if original_accomp_rms > 0:
                    original_ratio = original_voice_rms / original_accomp_rms
                    self.logger.info(f"ğŸ“Š åŸå§‹éŸ³é¢‘æ¯”ä¾‹åˆ†æ:")
                    self.logger.info(f"  åŸå§‹äººå£°RMS: {original_voice_rms:.6f}")
                    self.logger.info(f"  åŸå§‹èƒŒæ™¯éŸ³ä¹RMS: {original_accomp_rms:.6f}")
                    self.logger.info(f"  åŸå§‹äººå£°/èƒŒæ™¯éŸ³ä¹æ¯”ä¾‹: {original_ratio:.2f}x")
                    return (original_voice_rms, original_accomp_rms)
                else:
                    self.logger.warning("åŸå§‹èƒŒæ™¯éŸ³ä¹RMSä¸º0ï¼Œæ— æ³•è®¡ç®—æ¯”ä¾‹")
                    return (None, None)
            else:
                self.logger.warning("æœªæ‰¾åˆ°åŸå§‹äººå£°æˆ–èƒŒæ™¯éŸ³ä¹æ–‡ä»¶ï¼Œæ— æ³•åˆ†æåŸå§‹æ¯”ä¾‹")
                return (None, None)
        except Exception as e:
            self.logger.warning(f"åˆ†æåŸå§‹éŸ³é¢‘æ¯”ä¾‹å¤±è´¥: {e}")
            return (None, None)
    
    def _balance_audio_levels(self, voice_audio: np.ndarray, background_audio: np.ndarray, 
                             original_voice_rms: Optional[float] = None, 
                             original_accomp_rms: Optional[float] = None) -> np.ndarray:
        """
        å¹³è¡¡äººå£°å’ŒèƒŒæ™¯éŸ³ä¹çš„éŸ³é‡ï¼Œä¿æŒåŸå§‹éŸ³é¢‘çš„ç›¸å¯¹æ¯”ä¾‹
        
        Args:
            voice_audio: äººå£°éŸ³é¢‘æ•°æ®
            background_audio: èƒŒæ™¯éŸ³ä¹éŸ³é¢‘æ•°æ®
            original_voice_rms: åŸå§‹äººå£°RMSï¼ˆå¯é€‰ï¼‰
            original_accomp_rms: åŸå§‹èƒŒæ™¯éŸ³ä¹RMSï¼ˆå¯é€‰ï¼‰
            
        Returns:
            å¹³è¡¡åçš„éŸ³é¢‘æ•°æ®
        """
        try:
            # è®¡ç®—RMSéŸ³é‡
            voice_rms = np.sqrt(np.mean(voice_audio**2))
            background_rms = np.sqrt(np.mean(background_audio**2))
            
            self.logger.info(f"ğŸ”Š éŸ³é‡åˆ†æ:")
            self.logger.info(f"  å…‹éš†äººå£°RMS: {voice_rms:.4f}")
            self.logger.info(f"  èƒŒæ™¯éŸ³ä¹RMS: {background_rms:.4f}")
            
            # å¦‚æœæä¾›äº†åŸå§‹æ¯”ä¾‹ï¼Œä½¿ç”¨åŸå§‹æ¯”ä¾‹ï¼›å¦åˆ™ä½¿ç”¨å›ºå®šç›®æ ‡æ¯”ä¾‹
            if original_voice_rms is not None and original_accomp_rms is not None and original_accomp_rms > 0:
                # ä¿æŒåŸå§‹éŸ³é¢‘ä¸­èƒŒæ™¯éŸ³ä¹å’Œäººå£°çš„ç›¸å¯¹æ¯”ä¾‹
                original_ratio = original_voice_rms / original_accomp_rms
                self.logger.info(f"  ä½¿ç”¨åŸå§‹æ¯”ä¾‹: äººå£°/èƒŒæ™¯éŸ³ä¹ = {original_ratio:.2f}x")
                
                # ä¿®å¤ï¼šåŸºäºåŸå§‹äººå£°RMSè®¾ç½®ç›®æ ‡ï¼Œè€Œä¸æ˜¯å›ºå®š0.3-0.5
                # å¦‚æœå…‹éš†äººå£°RMS >= åŸå§‹äººå£°RMSï¼Œä½¿ç”¨åŸå§‹äººå£°RMSä½œä¸ºç›®æ ‡
                # å¦‚æœå…‹éš†äººå£°RMS < åŸå§‹äººå£°RMSï¼Œé€‚åº¦æ”¾å¤§ä½†ä¸è¶…è¿‡åŸå§‹äººå£°RMSçš„1.2å€
                if voice_rms > 0:
                    if voice_rms >= original_voice_rms:
                        # å…‹éš†äººå£°å·²ç»è¶³å¤Ÿå¤§ï¼Œä½¿ç”¨åŸå§‹äººå£°RMSä½œä¸ºç›®æ ‡ï¼ˆä¿æŒæˆ–ç•¥å¾®é™ä½ï¼‰
                        target_voice_rms = original_voice_rms
                        self.logger.info(f"  å…‹éš†äººå£°RMS ({voice_rms:.4f}) >= åŸå§‹äººå£°RMS ({original_voice_rms:.4f})ï¼Œä½¿ç”¨åŸå§‹äººå£°RMSä½œä¸ºç›®æ ‡")
                    else:
                        # å…‹éš†äººå£°è¾ƒå°ï¼Œé€‚åº¦æ”¾å¤§ä½†ä¸è¶…è¿‡åŸå§‹äººå£°RMSçš„1.2å€
                        target_voice_rms = min(original_voice_rms * 1.2, max(voice_rms, original_voice_rms * 0.9))
                        self.logger.info(f"  å…‹éš†äººå£°RMS ({voice_rms:.4f}) < åŸå§‹äººå£°RMS ({original_voice_rms:.4f})ï¼Œé€‚åº¦æ”¾å¤§åˆ° {target_voice_rms:.4f}")
                    
                    voice_gain = target_voice_rms / voice_rms
                    voice_gain = np.clip(voice_gain, 0.1, 3.0)  # é™åˆ¶äººå£°å¢ç›Š
                else:
                    voice_gain = 1.0
                    target_voice_rms = original_voice_rms if original_voice_rms else 0.3
                
                # æ ¹æ®åŸå§‹æ¯”ä¾‹ï¼Œè®¡ç®—èƒŒæ™¯éŸ³ä¹çš„ç›®æ ‡RMS
                target_background_rms = target_voice_rms / original_ratio
                
                # è®¡ç®—èƒŒæ™¯éŸ³ä¹å¢ç›Š
                if background_rms > 0:
                    background_gain = target_background_rms / background_rms
                    # é™åˆ¶èƒŒæ™¯éŸ³ä¹å¢ç›Šï¼Œé¿å…è¿‡åº¦æ”¾å¤§ï¼ˆæœ€å¤§1.2xï¼Œæ›´ä¿å®ˆï¼‰
                    # å¦‚æœè®¡ç®—å‡ºçš„å¢ç›Šå°äº1.0ï¼Œè¯´æ˜èƒŒæ™¯éŸ³ä¹å·²ç»è¶³å¤Ÿå¤§ï¼Œä¸éœ€è¦æ”¾å¤§
                    background_gain = np.clip(background_gain, 0.0, 1.2)
                    
                    # é¢å¤–æ£€æŸ¥ï¼šå¦‚æœç›®æ ‡èƒŒæ™¯éŸ³ä¹RMSæ¯”åŸå§‹èƒŒæ™¯éŸ³ä¹RMSå¤§å¾ˆå¤šï¼Œè¿›ä¸€æ­¥é™åˆ¶
                    if target_background_rms > original_accomp_rms * 1.5:
                        self.logger.warning(f"  âš ï¸ ç›®æ ‡èƒŒæ™¯éŸ³ä¹RMS ({target_background_rms:.4f}) æ¯”åŸå§‹èƒŒæ™¯éŸ³ä¹RMS ({original_accomp_rms:.4f}) å¤§å¾ˆå¤šï¼Œé™åˆ¶å¢ç›Š")
                        # é™åˆ¶ç›®æ ‡èƒŒæ™¯éŸ³ä¹RMSä¸è¶…è¿‡åŸå§‹èƒŒæ™¯éŸ³ä¹RMSçš„1.2å€
                        target_background_rms = original_accomp_rms * 1.2
                        background_gain = target_background_rms / background_rms
                        background_gain = np.clip(background_gain, 0.0, 1.2)
                    
                    # å…³é”®ä¿®å¤ï¼šå¦‚æœäººå£°è¢«é™ä½ï¼ˆå¢ç›Š<1.0ï¼‰ï¼ŒèƒŒæ™¯éŸ³ä¹ä¹Ÿåº”è¯¥ç›¸åº”é™ä½ï¼Œä»¥ä¿æŒç›¸å¯¹æ¯”ä¾‹
                    if voice_gain < 1.0 and background_gain > voice_gain:
                        self.logger.info(f"  ğŸ”§ äººå£°è¢«é™ä½ï¼ˆå¢ç›Š {voice_gain:.2f}xï¼‰ï¼Œé™åˆ¶èƒŒæ™¯éŸ³ä¹å¢ç›Šä¸è¶…è¿‡äººå£°å¢ç›Šï¼Œä»¥ä¿æŒç›¸å¯¹æ¯”ä¾‹")
                        background_gain = min(background_gain, voice_gain)
                        # é‡æ–°è®¡ç®—ç›®æ ‡èƒŒæ™¯éŸ³ä¹RMSï¼ˆåŸºäºé™åˆ¶åçš„å¢ç›Šï¼‰
                        target_background_rms = background_rms * background_gain
                else:
                    background_gain = 0.0
                
                self.logger.info(f"  ç›®æ ‡äººå£°RMS: {target_voice_rms:.4f} (åŸå§‹: {original_voice_rms:.4f})")
                self.logger.info(f"  ç›®æ ‡èƒŒæ™¯éŸ³ä¹RMS: {target_background_rms:.4f} (åŸå§‹: {original_accomp_rms:.4f}, ä¿æŒåŸå§‹æ¯”ä¾‹ {original_ratio:.2f}x)")
            else:
                # å›é€€åˆ°å›ºå®šç›®æ ‡æ¯”ä¾‹ï¼ˆå¦‚æœæ— æ³•è·å–åŸå§‹æ¯”ä¾‹ï¼‰
                self.logger.info(f"  ä½¿ç”¨å›ºå®šç›®æ ‡æ¯”ä¾‹ï¼ˆæ— æ³•è·å–åŸå§‹æ¯”ä¾‹ï¼‰")
                if voice_rms > 0.1:
                    voice_target_ratio = 0.5  # äººå£°å 50%
                else:
                    voice_target_ratio = 0.6  # äººå£°å 60%
                background_target_ratio = 0.2  # èƒŒæ™¯éŸ³ä¹å 20%ï¼ˆé™ä½ï¼Œå‡å°‘å¹²æ‰°ï¼‰
                
                # è®¡ç®—è°ƒæ•´ç³»æ•°
                if voice_rms > 0:
                    voice_gain = voice_target_ratio / voice_rms
                else:
                    voice_gain = 1.0
                    
                if background_rms > 0:
                    background_gain = background_target_ratio / background_rms
                else:
                    background_gain = 0.0
                
                # é™åˆ¶å¢ç›ŠèŒƒå›´
                voice_gain = np.clip(voice_gain, 0.1, 3.0)
                background_gain = np.clip(background_gain, 0.0, 1.5)  # é™ä½èƒŒæ™¯éŸ³ä¹æœ€å¤§å¢ç›Š
            
            self.logger.info(f"  äººå£°å¢ç›Š: {voice_gain:.2f}x")
            self.logger.info(f"  èƒŒæ™¯éŸ³ä¹å¢ç›Š: {background_gain:.2f}x")
            
            # åº”ç”¨å¢ç›Š
            balanced_voice = voice_audio * voice_gain
            balanced_background = background_audio * background_gain
            
            # é˜²æ­¢å‰Šæ³¢ï¼šåœ¨æ··åˆå‰æ£€æŸ¥å³°å€¼
            voice_peak = np.max(np.abs(balanced_voice))
            background_peak = np.max(np.abs(balanced_background))
            estimated_peak = voice_peak + background_peak
            
            if estimated_peak > 1.0:
                self.logger.warning(f"  âš ï¸ æ£€æµ‹åˆ°å¯èƒ½å‰Šæ³¢ï¼ˆä¼°è®¡å³°å€¼: {estimated_peak:.4f} > 1.0ï¼‰ï¼Œå…ˆå½’ä¸€åŒ–")
                # å¦‚æœä¼°è®¡å³°å€¼è¶…è¿‡1.0ï¼Œå…ˆå½’ä¸€åŒ–ä¸¤ä¸ªéŸ³é¢‘
                if voice_peak > 0:
                    balanced_voice = balanced_voice / max(voice_peak, 0.7)  # å½’ä¸€åŒ–åˆ°0.7ï¼Œç•™å‡ºç©ºé—´ç»™èƒŒæ™¯éŸ³ä¹
                if background_peak > 0:
                    balanced_background = balanced_background / max(background_peak, 0.3)  # å½’ä¸€åŒ–åˆ°0.3
            
            # åˆå¹¶éŸ³é¢‘
            final_audio = balanced_voice + balanced_background
            
            # æ£€æŸ¥æ··åˆåçš„å³°å€¼ï¼Œé˜²æ­¢å‰Šæ³¢
            final_peak = np.max(np.abs(final_audio))
            if final_peak > 1.0:
                self.logger.warning(f"  âš ï¸ æ··åˆåæ£€æµ‹åˆ°å‰Šæ³¢ï¼ˆå³°å€¼: {final_peak:.4f} > 1.0ï¼‰ï¼Œè¿›è¡Œå½’ä¸€åŒ–")
                final_audio = final_audio / final_peak * 0.99  # å½’ä¸€åŒ–åˆ°0.99ï¼Œé¿å…å®Œå…¨å‰Šæ³¢
            
            # è®¡ç®—æœ€ç»ˆéŸ³é‡
            final_rms = np.sqrt(np.mean(final_audio**2))
            final_peak_after = np.max(np.abs(final_audio))
            self.logger.info(f"  æœ€ç»ˆéŸ³é¢‘RMS: {final_rms:.4f}")
            self.logger.info(f"  æœ€ç»ˆå³°å€¼: {final_peak_after:.4f}")
            
            return final_audio
            
        except Exception as e:
            self.logger.error(f"éŸ³é¢‘éŸ³é‡å¹³è¡¡å¤±è´¥: {e}")
            # å¦‚æœå¹³è¡¡å¤±è´¥ï¼Œä½¿ç”¨ç®€å•ç›¸åŠ 
            return voice_audio + background_audio * 0.3
    
    def _normalize_audio_volume(self, audio: np.ndarray) -> np.ndarray:
        """
        ä¿æŒä¸åŸè§†é¢‘ç›¸è¿‘çš„éŸ³é‡ï¼Œåªåšè½»å¾®çš„å³°å€¼æ ‡å‡†åŒ–
        
        Args:
            audio: è¾“å…¥éŸ³é¢‘æ•°æ®
            
        Returns:
            æ ‡å‡†åŒ–åçš„éŸ³é¢‘æ•°æ®
        """
        try:
            # è®¡ç®—å½“å‰å³°å€¼
            current_peak = np.max(np.abs(audio))
            
            if current_peak == 0:
                self.logger.warning("éŸ³é¢‘æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡éŸ³é‡æ ‡å‡†åŒ–")
                return audio
            
            # é˜²æ­¢å‰Šæ³¢ï¼šå¦‚æœå³°å€¼å·²ç»è¶…è¿‡1.0ï¼Œå…ˆå½’ä¸€åŒ–
            if current_peak > 1.0:
                self.logger.warning(f"  âš ï¸ æ£€æµ‹åˆ°å‰Šæ³¢ï¼ˆå³°å€¼: {current_peak:.4f} > 1.0ï¼‰ï¼Œå…ˆå½’ä¸€åŒ–")
                audio = audio / current_peak * 0.99  # å½’ä¸€åŒ–åˆ°0.99
                current_peak = 0.99
            
            # ç›®æ ‡å³°å€¼ï¼šä¸åŸè§†é¢‘å®Œå…¨ä¸€è‡´æˆ–ç¨å¾®å°ä¸€ç‚¹ç‚¹
            # å¦‚æœåŸå§‹å³°å€¼å·²ç»å¾ˆé«˜ï¼Œç¨å¾®é™ä½5%ï¼›å¦‚æœè¾ƒä½ï¼Œé€‚å½“æå‡
            if current_peak > 0.95:
                target_peak = current_peak * 0.95  # ç¨å¾®é™ä½5%
            elif current_peak > 0.8:
                target_peak = 0.9  # é€‚å½“æå‡åˆ°90%
            else:
                target_peak = 0.9  # æå‡åˆ°90%
            
            # è®¡ç®—å¢ç›Š
            gain = target_peak / current_peak
            
            # é™åˆ¶å¢ç›ŠèŒƒå›´ï¼Œé¿å…è¿‡åº¦æ”¾å¤§æˆ–ç¼©å°
            # å¦‚æœéŸ³é¢‘å·²ç»å¾ˆå“ï¼Œç¨å¾®é™ä½ï¼›å¦‚æœè¾ƒä½ï¼Œé€‚åº¦æå‡
            if current_peak > 0.95:
                gain = 0.95  # ç¨å¾®é™ä½5%
            elif current_peak > 0.8:
                gain = min(gain, 1.2)  # æœ€å¤šæ”¾å¤§20%
            else:
                gain = min(gain, 1.5)  # æœ€å¤šæ”¾å¤§50%ï¼ˆé™ä½ä»2.0åˆ°1.5ï¼‰
            
            # åº”ç”¨å¢ç›Š
            normalized_audio = audio * gain
            
            # å†æ¬¡æ£€æŸ¥å³°å€¼ï¼Œç¡®ä¿ä¸è¶…è¿‡1.0
            final_peak = np.max(np.abs(normalized_audio))
            if final_peak > 1.0:
                self.logger.warning(f"  âš ï¸ å¢ç›Šåæ£€æµ‹åˆ°å‰Šæ³¢ï¼ˆå³°å€¼: {final_peak:.4f} > 1.0ï¼‰ï¼Œè¿›è¡Œæœ€ç»ˆå½’ä¸€åŒ–")
                normalized_audio = normalized_audio / final_peak * 0.99
                final_peak = 0.99
            
            # è®¡ç®—æœ€ç»ˆéŸ³é‡ä¿¡æ¯
            final_rms = np.sqrt(np.mean(normalized_audio**2))
            
            self.logger.info(f"ğŸ”Š éŸ³é‡è°ƒæ•´:")
            self.logger.info(f"  åŸå§‹å³°å€¼: {current_peak:.4f}")
            self.logger.info(f"  ç›®æ ‡å³°å€¼: {target_peak:.4f}")
            self.logger.info(f"  åº”ç”¨å¢ç›Š: {gain:.2f}x")
            self.logger.info(f"  æœ€ç»ˆRMS: {final_rms:.4f}")
            self.logger.info(f"  æœ€ç»ˆå³°å€¼: {final_peak:.4f}")
            
            return normalized_audio
            
        except Exception as e:
            self.logger.error(f"éŸ³é‡è°ƒæ•´å¤±è´¥: {e}")
            # å¦‚æœè°ƒæ•´å¤±è´¥ï¼Œä¿æŒåŸéŸ³é‡
            return audio
